\section{Results}
In general, non-normalized data blows up some calculation.
In sigmoid, it is the exponential $wX+b$; in linear, because of $A^2$ in the cost. Here also the learning rate can be really large (up to 100) and the code optimizes well. With smaller learning rates, we need more cycles.

The backward propagation ends up being the same for both methods (apart from a constant). Hence it is useful for both methods. The cost is different though.

