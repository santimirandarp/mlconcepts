# Linear Regression as described on the docs
import ds
import numpy as np 
import matplotlib.pyplot as plt

X = np.array([[1.01,2.01,3.05,4], [0.98,2.05,3.1,5]])
Y = np.array([[1.01,2.02,2.88,4.1]])
### (2,4) (4, 1)

# forward prop
def cost(X,Y,Yp):
    # we need Yp, comes from predict
    # returns cost
    m = X.shape[1]
    A = Y-Yp
    cost=1/m*np.power(2,A)    
    return A, cost
def predict(X,w,b):
    #we need w,b, comes from initialize
    #returns Yp
    Yp = np.dot(w,X)-b # 1x4
    return Yp

def initialize(dim):
    # dim is X.shape[0]
    w = np.zeros((1, dim))
    b = 0
    return w, b


# backward prop
def update(X,A,w,b,lr=1):
   m = X.shape[1]
   dw = np.sum(A*X, axis=1, keepdims=True)*lr
   w = w + dw 
   b = b + A*lr
   return w, b

def model(X, Y, numIt):
    w,b = initialize(X.shape[0])
    for i in range(numIt):
        Yp = predict(X,w,b)
        A, c = cost(X,Y,Yp)
        w,b = update(X,A,w,b,lr=1)
    print("cost: ", c)

model(X,Y,5)
